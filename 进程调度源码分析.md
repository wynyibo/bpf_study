# 进程调度源码分析

## 调度 为啥 怎么 意义

## O(N)调度

### 算法思想 

### 具体实现
``` c
asmlinkage void schedule(void)
{
	struct schedule_data * sched_data;
	struct task_struct *prev, *next, *p;
	struct list_head *tmp;
	int this_cpu, c;

	if (!current->active_mm) BUG();
need_resched_back:
	prev = current;
	this_cpu = prev->processor;

	if (in_interrupt())
		goto scheduling_in_interrupt;

	release_kernel_lock(prev, this_cpu);

	/* Do "administrative" work here while we don't hold any locks */
	if (softirq_active(this_cpu) & softirq_mask(this_cpu))
		goto handle_softirq;
handle_softirq_back:

	/*
	 * 'sched_data' is protected by the fact that we can run
	 * only one process per CPU.
	 */
	sched_data = & aligned_data[this_cpu].schedule_data;

	spin_lock_irq(&runqueue_lock);

	/* move an exhausted RR process to be last.. */
	if (prev->policy == SCHED_RR)
		goto move_rr_last;
move_rr_back:

	switch (prev->state) {
		case TASK_INTERRUPTIBLE:
			if (signal_pending(prev)) {
				prev->state = TASK_RUNNING;
				break;
			}
		default:
			del_from_runqueue(prev);
		case TASK_RUNNING:
	}
	prev->need_resched = 0;

	/*
	 * this is the scheduler proper:
	 */

repeat_schedule:
	/*
	 * Default process to select..
	 */
	next = idle_task(this_cpu);
	c = -1000;
	if (prev->state == TASK_RUNNING)
		goto still_running;

still_running_back:
	list_for_each(tmp, &runqueue_head) {
		p = list_entry(tmp, struct task_struct, run_list);
		if (can_schedule(p, this_cpu)) {
			int weight = goodness(p, this_cpu, prev->active_mm);
			if (weight > c)
				c = weight, next = p;
		}
	}

	/* Do we need to re-calculate counters? */
	if (!c)
		goto recalculate;
	/*
	 * from this point on nothing can prevent us from
	 * switching to the next task, save this fact in
	 * sched_data.
	 */
	sched_data->curr = next;
#ifdef CONFIG_SMP
 	next->has_cpu = 1;
	next->processor = this_cpu;
#endif
	spin_unlock_irq(&runqueue_lock);

	if (prev == next)
		goto same_process;

#ifdef CONFIG_SMP
 	/*
 	 * maintain the per-process 'last schedule' value.
 	 * (this has to be recalculated even if we reschedule to
 	 * the same process) Currently this is only used on SMP,
	 * and it's approximate, so we do not have to maintain
	 * it while holding the runqueue spinlock.
 	 */
 	sched_data->last_schedule = get_cycles();

	/*
	 * We drop the scheduler lock early (it's a global spinlock),
	 * thus we have to lock the previous process from getting
	 * rescheduled during switch_to().
	 */

#endif /* CONFIG_SMP */

	kstat.context_swtch++;
	/*
	 * there are 3 processes which are affected by a context switch:
	 *
	 * prev == .... ==> (last => next)
	 *
	 * It's the 'much more previous' 'prev' that is on next's stack,
	 * but prev is set to (the just run) 'last' process by switch_to().
	 * This might sound slightly confusing but makes tons of sense.
	 */
	prepare_to_switch();
	{
		struct mm_struct *mm = next->mm;
		struct mm_struct *oldmm = prev->active_mm;
		if (!mm) {
			if (next->active_mm) BUG();
			next->active_mm = oldmm;
			atomic_inc(&oldmm->mm_count);
			enter_lazy_tlb(oldmm, next, this_cpu);
		} else {
			if (next->active_mm != mm) BUG();
			switch_mm(oldmm, mm, next, this_cpu);
		}

		if (!prev->mm) {
			prev->active_mm = NULL;
			mmdrop(oldmm);
		}
	}

	/*
	 * This just switches the register state and the
	 * stack.
	 */
	switch_to(prev, next, prev);
	__schedule_tail(prev);

same_process:
	reacquire_kernel_lock(current);
	if (current->need_resched)
		goto need_resched_back;

	return;

recalculate:
	{
		struct task_struct *p;
		spin_unlock_irq(&runqueue_lock);
		read_lock(&tasklist_lock);
		for_each_task(p)
			p->counter = (p->counter >> 1) + NICE_TO_TICKS(p->nice);
		read_unlock(&tasklist_lock);
		spin_lock_irq(&runqueue_lock);
	}
	goto repeat_schedule;

still_running:
	c = goodness(prev, this_cpu, prev->active_mm);
	next = prev;
	goto still_running_back;

handle_softirq:
	do_softirq();
	goto handle_softirq_back;

move_rr_last:
	if (!prev->counter) {
		prev->counter = NICE_TO_TICKS(prev->nice);
		move_last_runqueue(prev);
	}
	goto move_rr_back;

scheduling_in_interrupt:
	printk("Scheduling in interrupt\n");
	BUG();
	return;
}
```


​	细节处理

​	
## O(1)调度
### 算法思想 
把原先的就绪队列的单个链表变成了多个链表，每一个优先级的进程被挂入到不同的链表里面，系统中所有的就绪进程首先经过负载均衡模块挂入各个CPU的就绪队列上，然后由主调度器和周期性调度器驱动该CPU上的调度行为,

![Alt text](image-1.png)
**runqueue结构**

每个CPU都需要维护一个 runqueue 结构，runqueue 结构主要维护任务调度相关的信息，比如优先队列、调度次数、CPU负载信息等。
``` c
struct runqueue {
    spinlock_t lock;
    unsigned long nr_running,
                  nr_switches,
                  expired_timestamp,
                  nr_uninterruptible;
    task_t *curr, *idle;
    struct mm_struct *prev_mm;
    prio_array_t *active, *expired, arrays[2];  //prio_array_t即为后文的prio_array
    int prev_cpu_load[NR_CPUS];
    task_t *migration_thread;
    struct list_head migration_queue;
    atomic_t nr_iowait;
};
```
`active`和`expired`指针类型为 `prio_array`，其分别指向array[0]、array[1]，其中active代表可以调度的任务队列，而expired字段代表时间片已经用完的任务队列，当active中的任务时间片用完，那么就会被移动到expired中。

![Alt text](image-2.png)

其中为了保证交互式/实时进程的响应时间，当此类进程时间片为0时，重置其时间片并重新插入active数组，但其不能一直呆在active数组中，会导致expired中的数饥饿，所有当其占用CPU时间达到一个固定值时，将其转移到expired中，当active中已经没有任务可以运行，就把 expired与active调转。

**优先级数组的结构**

```c
struct prio_array
{
	unsigned int nr_active;
	unsigned long bitmap[BITMAP_SIZE];
	struct list_head queue[MAX_PRIO];
};
```

![Alt text](image.png)
队列成员中有140个分别表示各优先级的链表头，其中100-139是普通进程的优先级，其余是实时进程的优先级，其被分开来进行管理，不同优先级的进程被挂入不同的链表中，`bitmap`用来表示各个优先级进程链表是空还是非空。`nr_avtive`是表示总任务数，当进行调度时，通过位图找到非空进程队列，即可以常数的时间级找到要调度的进程






<!-- 
##### 主调度器schedule函数

从CPU就绪队列中找到合适的进程进行调度：首先从当前活跃队列的位图中寻找第一个非空的进程链表，然后从该链表中找到第一个结点，即为最适合的进程，由于没有对结构进行遍历，其时间复杂度为O(1)，但其用复杂算法来判断进程是不是交互式进程以及进程的交互次数

使用机制和策略分离的思想，将其分为两大部分，第一个部分通过负载均衡模块将各个就绪状态的任务根据负载情况平均分配到各个CPU就绪队列上，第二部分实在各个CPU的著调度器和周期性调度器的驱动下进行单个CPU上的调度,将这部分共同的逻辑抽象出来，称为**核心调度器层**

我们也可以根据各个类型的调度器来定义自己的调度类，并以链表的形式加入到系统中

##### 调度器类

###### 实时进程调度
实时进程分为 FIFO（先进先出） 和 RR（时间轮询） 两种，其调度算法比较简单，如下：

**先进先出的实时进程调度**：如果调度器在执行某个先进先出的实时进程，那么调度器会一直运行这个进程，直至其主动放弃运行权

**时间轮询的实时进程调度**：如果调度器在执行某个时间轮询的实时进程，那么调度器会判断当前进程的时间片是否用完，如果用完的话，那么重新分配时间片给它，并且重新放置回 active 队列中，然后调度到其他同优先级或者优先级更高的实时进程进行运行

###### 普通进程调度
每个进程都要一个动态优先级和静态优先级，静态优先级不会变化在进程创建时被设置，而动态优先级会随着进程的睡眠时间而发生变化。动态优先级可以通过以下公式进行计算：

`动态优先级 = max(100, min(静态优先级 – bonus + 5), 139))`

上面公式的 bonus（奖励或惩罚） 是通过进程的睡眠时间计算出来，进程的睡眠时间越大，bonus 的值就越大，那么动态优先级就越高（前面说过优先级的值越小，优先级越高）。

当一个普通进程被添加到运行队列时，会先计算其动态优先级，然后按照动态优先级的值来添加到对应优先级的队列中。而调度器调度进程时，会先选择优先级最高的任务队列中的进程进行调度运行。

当进程的时间用完后，就需要重新进行计算。进程的运行时间片与静态优先级有关，可以通过以下公式进行计算：
```
静态优先级 < 120，运行时间片 = max((140-静态优先级)*20, MIN_TIMESLICE)
静态优先级 >= 120，运行时间片 = max((140-静态优先级)*5, MIN_TIMESLICE)
``` -->



### 具体实现 

``` c
asmlinkage void schedule(void)//asmlinkage标志指示编译器使用汇编语法的调用约定
{
	task_t *prev, *next;	//prve表示调度之间的进程，next表示调度之后的进程
	runqueue_t *rq; 		//存储就绪队列的结构 
	prio_array_t *array;	//prio_array结构 存储进程队列
	struct list_head *queue;//链表
	unsigned long long now;	//当前时间
	unsigned long run_time;	//进程运行时间
	int idx;				//索引值

	//检查当前进程是否为TASK_DEAD终止态或TASK_ZOMBIE僵尸态
	//likely 用于提示编译器这是一个常见情况，可以优化代码执行。
	if (likely(!(current->state & (TASK_DEAD | TASK_ZOMBIE)))) {
		if (unlikely(in_atomic())) {	//likely 用于提示编译器这是一个常见情况，可以优化代码执行。
			printk(KERN_ERR "bad: scheduling while atomic!\n");
			dump_stack();//记录当前的调用栈信息 帮助开发人员识别问题
		}
	}

//先禁止抢占，再初始化一些变量,需要访问任务的运行队列
need_resched:
	preempt_disable(); //禁用内核的抢占
	prev = current; 	//存储当前进程
	rq = this_rq();		//获取当前运行队列的指针

	release_kernel_lock(prev); 	//释放当前任务所占用的内核锁
	now = sched_clock();		//获取当前时间
	//检查当前任务的运行时间是否小于NS_MAX_SLEEP_AVG，取二者的小值
	if (likely(now - prev->timestamp < NS_MAX_SLEEP_AVG))
		run_time = now - prev->timestamp;
	else
		run_time = NS_MAX_SLEEP_AVG;

	//检查当前任务是否有高优先级的信用
	if (HIGH_CREDIT(prev))//对有较长睡眠时间的进程，进行一定奖励
		run_time /= (CURRENT_BONUS(prev) ? : 1);//将 run_time 除以当前任务的奖励，否则除以1

    //在开始寻找可运行进程之前，需要关中断并获得保护运行队列的自旋锁
	spin_lock_irq(&rq->lock); //获取运行队列的锁，以确保对运行队列的访问是原子的，不会被中断。

	//解释了在从内核抢占状态进入时，直接跳到选择下一个任务的原因
	if (unlikely(preempt_count() & PREEMPT_ACTIVE)) //用于检查当前是否处于抢占活动状态
		goto pick_next_task; //直接跳转到选择下一进程

	switch (prev->state) {//判断先前进程的状态
	case TASK_INTERRUPTIBLE://用当前处于可抢占活动状态
		if (unlikely(signal_pending(prev))) { //检查当前任务是否有挂起的信号
			prev->state = TASK_RUNNING;	//将当前任务的状态设置为TASK_RUNNING
			break;
		}
	default:
		deactivate_task(prev, rq);//不是可中断等待状态或没有挂起的信号，将当前任务从运行队列中移除。
		prev->nvcsw++;//增加当前任务的非抢占式上下文切换计数
		break;
	case TASK_RUNNING:
		prev->nivcsw++;//增加当前任务的非抢占式上下文切换计数
	}
pick_next_task:
	if (unlikely(!rq->nr_running)) {//检查当前运行队列中是否没有正在运行的任务
#ifdef CONFIG_SMP //是否启用了多处理器（SMP）支持
		load_balance(rq, 1, cpu_to_node_mask(smp_processor_id()));//进行负载均衡操作
		if (rq->nr_running)
			goto pick_next_task;
#endif
		next = rq->idle;//如果没有需要运行的任务，将 next 指向运行队列的空闲任务
		//expired_timestamp表示当前队列中，过期队列中最老进程被插入过期队列的时间。
		rq->expired_timestamp = 0;//将运行队列的 expired_timestamp 设置为0。
		goto switch_tasks;//跳转到切换模块
	}

	array = rq->active;//将array赋为active队列
	if (unlikely(!array->nr_active)) {//检查array中是否没有等待运行的任务
		//交换active与expired指针,实现结构调转
		rq->active = rq->expired;
		rq->expired = array;
		array = rq->active;
		rq->expired_timestamp = 0;
	}

	idx = sched_find_first_bit(array->bitmap);//在位图中查找下一个要调度的索引
	queue = array->queue + idx;//根据索引idx获取任务队列中的相应队列头节点
	next = list_entry(queue->next, task_t, run_list);//获取下一个要运行的任务
	/*activated表达的是从什么状态被唤醒
	0，进程处于TASK_RUNNING状态；
	1，进程处于TASK_INTERRUPTIBLE或者TASK_STOPPED状态，常见例子就是被信号唤醒
	2，进程处于TASK_INTERRUPTIBLE或者TASK_STOPPED状态，常见例子就是IO中断；
	-1，表示从UNINTERRUPTIBLE状态被唤醒。
	*/
	if (next->activated > 0) {//检查下一个任务的激活状态是否大于0
		unsigned long long delta = now - next->timestamp;//计算当前时间 now 与下一个任务的时间戳之间的时间差

		if (next->activated == 1)//检查下一个任务的激活状态是否等于1
			delta = delta * (ON_RUNQUEUE_WEIGHT * 128 / 100) / 128;//根据特定权重和比例，调整 delta 的值

		array = next->array;//指向下一进程的prio_array结构
		dequeue_task(next, array);//将下一个任务从数组中的队列中移除
		recalc_task_prio(next, next->timestamp + delta);//重新计算下一个任务的优先级，考虑时间差 delta
		enqueue_task(next, array);//将下一个任务重新加入到队列中。
	}
	next->activated = 0;//将下一个任务的激活状态设置为0，表示它不再激活
switch_tasks:
	prefetch(next);//预取下一个任务 next 的数据。预取是一种优化技术，用于提前将数据加载到高速缓存，以提高程序执行的效率。
	clear_tsk_need_resched(prev);//清除前一个任务 prev 的重新调度标志
	RCU_qsctr(task_cpu(prev))++;//用于跟踪前一个任务的统计信息的操作，通常与 RCU（Read-Copy-Update）机制有关

	prev->sleep_avg -= run_time;//减去前一个任务的 sleep_avg 值，这表示前一个任务经过了一段时间的运行，其睡眠平均值会相应减少。
	if ((long)prev->sleep_avg <= 0){//如果前一个任务的 sleep_avg 小于等于0，将其设置为0
		prev->sleep_avg = 0;
		if (!(HIGH_CREDIT(prev) || LOW_CREDIT(prev)))//检查前一个任务是否既不是高优先级任务也不是低优先级任务。
			prev->interactive_credit--;//减少前一个任务的交互式信用
	}
	prev->timestamp = now;//更新前一个任务的时间戳，使其与当前时间 now 同步

	if (likely(prev != next)) {//检查前一个任务 prev 是否与下一个任务 next 不同
		next->timestamp = now;//将下一个任务 next 的时间戳更新为当前时间 now
		rq->nr_switches++;//增加运行队列 rq 的切换次数计数，表示进行了一次任务切换
		rq->curr = next;//将运行队列 rq 的当前任务指针更新为下一个任务 next，表示下一个任务将成为当前任务。

		prepare_arch_switch(rq, next);//执行体系结构相关的任务切换准备操作
		prev = context_switch(rq, prev, next);//执行任务切换操作，将前一个任务 prev 切换到下一个任务 next。这是任务切换的核心操作
		barrier();//执行任务切换操作，将前一个任务 prev 切换到下一个任务 next。这是任务切换的核心操作

		finish_task_switch(prev);//完成任务切换，通常执行一些收尾工作
	} else
		spin_unlock_irq(&rq->lock);//如果前一个任务与下一个任务相同（即没有进行任务切换），则解锁运行队列 rq 的锁。

	reacquire_kernel_lock(current);//重新获取内核锁。
	preempt_enable_no_resched();//启用抢占
	if (test_thread_flag(TIF_NEED_RESCHED))//检查是否需要重新调度任务
		goto need_resched;//跳转到 need_resched 
}
```

context_switch(rq, prev, next);

```c
//context_switch - 切换到新的虚存和新线程的寄存器状态。
static inline task_t * context_switch(runqueue_t *rq, task_t *prev, task_t *next)
{
	struct mm_struct *mm = next->mm;
	struct mm_struct *oldmm = prev->active_mm;

	if (unlikely(!mm)) {
 		next->active_mm = oldmm;
 		atomic_inc(&oldmm->mm_count);
 		enter_lazy_tlb(oldmm, next);
 	} else
 		switch_mm(oldmm, mm, next);

 	if (unlikely(!prev->mm)) {
  		prev->active_mm = NULL;
 		WARN_ON(rq->prev_mm);
 		rq->prev_mm = oldmm;
 	}

 	/* Here we just switch the register state and the stack. */
 	switch_to(prev, next, prev);

 	return prev;
}
```

<!-- #### 时钟中断

时钟中断是由硬件触发的，可以通过编程来设置其频率，Linux内核一般设置为每秒产生100 ~ 1000次。时钟中断会触发调用 scheduler_tick() 内核函数，其主要工作是：减少进程的可运行时间片，如果时间片用完，那么把进程从 active 队列移动到 expired 队列中。代码如下： -->

## 对比 总结 感悟 
